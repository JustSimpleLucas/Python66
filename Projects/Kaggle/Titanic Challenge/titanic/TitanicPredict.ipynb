{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f6a5d9-c4f9-44be-aa22-a74d918e424c",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b20af7e-0153-4425-806a-9ff549b6d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e1a7a-3435-47be-bdd3-387af70fb3c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "609b79fc-af3a-4196-94e5-c0a309bdd0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dragonsave/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  Sex_male  \\\n",
       "0            1         0       3  22.0      1      0   7.2500       1.0   \n",
       "1            2         1       1  38.0      1      0  71.2833       0.0   \n",
       "2            3         1       3  26.0      0      0   7.9250       0.0   \n",
       "3            4         1       1  35.0      1      0  53.1000       0.0   \n",
       "4            5         0       3  35.0      0      0   8.0500       1.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0         0.0         1.0  \n",
       "1         0.0         0.0  \n",
       "2         0.0         1.0  \n",
       "3         0.0         1.0  \n",
       "4         0.0         1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Handle missing values\n",
    "# For Age: Fill with median value\n",
    "train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
    "test_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n",
    "\n",
    "# For Embarked in training set: Fill with the most frequent value\n",
    "train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# For Fare in test set: Fill with median value of training set\n",
    "test_df['Fare'].fillna(train_df['Fare'].median(), inplace=True)\n",
    "\n",
    "# Drop columns that might not be immediately useful\n",
    "drop_columns = ['Name', 'Ticket', 'Cabin']\n",
    "train_df = train_df.drop(columns=drop_columns)\n",
    "test_df = test_df.drop(columns=drop_columns)\n",
    "\n",
    "# Convert categorical variables to numeric using one-hot encoding\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)  # Drop first to avoid dummy variable trap\n",
    "\n",
    "# For training data\n",
    "train_encoded = encoder.fit_transform(train_df[['Sex', 'Embarked']])\n",
    "train_encoded_df = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out(['Sex', 'Embarked']))\n",
    "train_df = pd.concat([train_df, train_encoded_df], axis=1).drop(columns=['Sex', 'Embarked'])\n",
    "\n",
    "# For test data\n",
    "test_encoded = encoder.transform(test_df[['Sex', 'Embarked']])\n",
    "test_encoded_df = pd.DataFrame(test_encoded, columns=encoder.get_feature_names_out(['Sex', 'Embarked']))\n",
    "test_df = pd.concat([test_df, test_encoded_df], axis=1).drop(columns=['Sex', 'Embarked'])\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PassengerId: Identifier for each passenger.\n",
    "Survived: Target variable (1 for survived, 0 for deceased).\n",
    "Pclass: Ticket class.\n",
    "Age: Age of the passenger.\n",
    "SibSp: Number of siblings/spouses aboard.\n",
    "Parch: Number of parents/children aboard.\n",
    "Fare: Ticket fare.\n",
    "Sex_male: Binary indicator for male gender (1 for male, 0 for female).\n",
    "Embarked_Q: Binary indicator for embarkation from Queenstown.\n",
    "Embarked_S: Binary indicator for embarkation from Southampton.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8882328-9ea8-4a46-aa37-2d77ee433479",
   "metadata": {},
   "source": [
    "# Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9026b64-a12a-4f01-ab40-220b745b39c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.8100558659217877\n",
      "Random forest accuracy: 0.8212290502793296\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and validation sets\n",
    "X = train_df.drop(columns=['PassengerId', 'Survived'])\n",
    "y = train_df['Survived']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=500, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_val_predictions = logreg.predict(X_val)\n",
    "logreg_val_accuracy = accuracy_score(y_val, logreg_val_predictions)\n",
    "\n",
    "# Training Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_val_predictions = rf.predict(X_val)\n",
    "rf_val_accuracy = accuracy_score(y_val, rf_val_predictions)\n",
    "\n",
    "print(f\"Logistic regression accuracy: {logreg_val_accuracy}\")\n",
    "print(f\"Random forest accuracy: {rf_val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cd50f30-f8ed-49a0-962b-f28e8d6b26b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9789325842696629,\n",
       " 0.8212290502793296,\n",
       "       Feature  Importance\n",
       " 5    Sex_male    0.273316\n",
       " 4        Fare    0.272058\n",
       " 1         Age    0.252745\n",
       " 0      Pclass    0.078616\n",
       " 2       SibSp    0.052192\n",
       " 3       Parch    0.038490\n",
       " 7  Embarked_S    0.023095\n",
       " 6  Embarked_Q    0.009488)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking overfitting by comparing training and test accuracy\n",
    "rf_train_predictions = rf.predict(X_train)\n",
    "rf_train_accuracy = accuracy_score(y_train, rf_train_predictions)\n",
    "\n",
    "# Getting feature importance from the Random Forest model\n",
    "feature_importance = rf.feature_importances_\n",
    "features_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "rf_train_accuracy, rf_val_accuracy, features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba7bbfea-a38a-46cd-bb08-1e98c9942608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044692737430168"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing less important features\n",
    "X_train_reduced = X_train.drop(columns=['Embarked_S', 'Embarked_Q'])\n",
    "X_val_reduced = X_val.drop(columns=['Embarked_S', 'Embarked_Q'])\n",
    "\n",
    "# Retraining the adjusted Random Forest model on the reduced dataset\n",
    "rf_adjusted.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Checking performance on the reduced validation set\n",
    "rf_adjusted_val_predictions_reduced = rf_adjusted.predict(X_val_reduced)\n",
    "rf_adjusted_val_accuracy_reduced = accuracy_score(y_val, rf_adjusted_val_predictions_reduced)\n",
    "\n",
    "rf_adjusted_val_accuracy_reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c30e5e5c-c8f9-4a48-b3bc-61c83bef9dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8946629213483146, 0.8212290502793296)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retraining the Random Forest with adjusted hyperparameters to reduce overfitting\n",
    "rf_adjusted = RandomForestClassifier(random_state=42, max_depth=10, min_samples_split=10)\n",
    "rf_adjusted.fit(X_train, y_train)\n",
    "\n",
    "# Checking performance on training and validation sets\n",
    "rf_adjusted_train_predictions = rf_adjusted.predict(X_train)\n",
    "rf_adjusted_val_predictions = rf_adjusted.predict(X_val)\n",
    "\n",
    "rf_adjusted_train_accuracy = accuracy_score(y_train, rf_adjusted_train_predictions)\n",
    "rf_adjusted_val_accuracy = accuracy_score(y_val, rf_adjusted_val_predictions)\n",
    "\n",
    "rf_adjusted_train_accuracy, rf_adjusted_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0592b6bf-1ede-4905-9405-1b47e8a9b1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 5, 'min_samples_split': 2}, 0.8356446370530877)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the hyperparameters and their possible values\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_grid = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up the grid search\n",
    "grid_search = GridSearchCV(rf_grid, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "best_val_accuracy = grid_search.best_score_\n",
    "\n",
    "best_params, best_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "370ebf53-1803-4caa-8dea-f1e90b250762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8156424581005587"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Random Forest model with the optimal hyperparameters\n",
    "rf_optimal = RandomForestClassifier(max_depth=5, min_samples_split=2, random_state=42)\n",
    "rf_optimal.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the model on the validation set\n",
    "rf_optimal_val_predictions = rf_optimal.predict(X_val)\n",
    "rf_optimal_val_accuracy = accuracy_score(y_val, rf_optimal_val_predictions)\n",
    "\n",
    "rf_optimal_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "619fd476-c7d5-45da-a930-aa4c2486f3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions on the provided test set using the Random Forest Classifier\n",
    "test_data = test_df.drop(columns=['PassengerId'])\n",
    "rf_test_predictions = rf.predict(test_data)\n",
    "\n",
    "# Making predictions on the provided test set using the optimal Random Forest model\n",
    "rf_optimal_test_predictions = rf_optimal.predict(test_data)\n",
    "\n",
    "# Creating the submission dataframe\n",
    "submission_optimal_df = pd.DataFrame({\n",
    "    \"PassengerId\": test_df[\"PassengerId\"],\n",
    "    \"Survived\": rf_optimal_test_predictions\n",
    "})\n",
    "\n",
    "submission_optimal_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "740bda4d-521e-4d2d-b1ce-5e05e0ce0037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dragonsave/Documents/Master behavior finance/Kaggle/Titanic Challenge/titanic_submission.csv'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the submission dataframe to a CSV file\n",
    "submission_file_path = \"/Users/dragonsave/Documents/Master behavior finance/Kaggle/Titanic Challenge/titanic_submission.csv\"\n",
    "submission_optimal_df.to_csv(submission_file_path, index=False)\n",
    "\n",
    "submission_file_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
